{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a6560c-3db8-4fe4-b0dc-2dd7e626760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone  # Added timezone\n",
    "import os\n",
    "import re  # For removing commas from database timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19085f3d-3458-409e-878a-c5e42f2d6c58",
   "metadata": {},
   "source": [
    "# PostgreSQL Location Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85cc9478-b2c9-4db2-86be-5abb218e99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"SafetyTracker\"\n",
    "DB_USER = \"kiet\"\n",
    "DB_PASSWORD = \"kietvo17112003\"\n",
    "\n",
    "DECRYPT_SCRIPT_PATH = \"./decrypt.py\"\n",
    "PRIVATE_KEY = \"hUotVQIdoniIfacuUNHahmnNK98GRV6+kn+sOQ==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0c5eca-92bd-4dc6-8680-061401bcd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def connect_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT,\n",
    "            dbname=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "        )\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error connecting to PostgreSQL database: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_raw_movement_data(conn):\n",
    "    if not conn:\n",
    "        return None\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # Ensure you select the correct columns that you'll use\n",
    "            cur.execute(\n",
    "                'SELECT \"LocationID\", \"DeviceID\", \"DatePublished\" AS \"DBDatePublished\", \"Payload\" AS \"EncryptedPayloadDB\", \"Description\" AS \"DBDescription\", \"StatusCode\" AS \"DBStatusCode\" FROM \"DeviceLocation\" ORDER BY \"LocationID\";'\n",
    "            )\n",
    "            colnames = [desc[0] for desc in cur.description]\n",
    "            rows = cur.fetchall()\n",
    "            return pd.DataFrame(rows, columns=colnames)\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def decrypt_payload_data(payload_str, private_key_val_or_path):\n",
    "    if (\n",
    "        not payload_str or pd.isna(payload_str) or payload_str.strip() == \"[NULL]\"\n",
    "    ):  # Handle [NULL] string\n",
    "        return None\n",
    "\n",
    "    command = [\n",
    "        \"python3\",\n",
    "        DECRYPT_SCRIPT_PATH,\n",
    "        str(private_key_val_or_path),\n",
    "        payload_str,\n",
    "    ]\n",
    "    try:\n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        decrypted_output_str = result.stdout.strip()\n",
    "        # Let's try to parse it as a list first, then as an object.\n",
    "        try:\n",
    "            parsed_json = json.loads(decrypted_output_str)\n",
    "            if isinstance(parsed_json, list) and len(parsed_json) > 0:\n",
    "                return parsed_json[0]  # Return the first object if it's a list\n",
    "            elif isinstance(parsed_json, dict):\n",
    "                return parsed_json  # Return the object if it's a dictionary\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Decrypted payload is not a recognized JSON object or list: {decrypted_output_str}\"\n",
    "                )\n",
    "                return None\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\n",
    "                f\"Error decoding JSON from decrypted payload '{decrypted_output_str}': {e}\"\n",
    "            )\n",
    "            return None\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\n",
    "            f\"Error during decryption script execution for payload '{payload_str[:30]}...': {e}\"\n",
    "        )\n",
    "        print(f\"Stderr: {e.stderr}\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Decryption script not found at {DECRYPT_SCRIPT_PATH}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during decryption: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faffcc05-8251-4892-a8d1-a1adf47d7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_movement_data(raw_df):\n",
    "    if raw_df is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    processed_data_list = []\n",
    "    for index, row in raw_df.iterrows():\n",
    "        db_location_id = row[\"LocationID\"]\n",
    "        db_device_id = row[\"DeviceID\"] # From DB\n",
    "        encrypted_payload_db = row[\"EncryptedPayloadDB\"]\n",
    "\n",
    "        # Initialize fields to be extracted from decrypted payload\n",
    "        actual_timestamp_utc = None\n",
    "        latitude = None\n",
    "        longitude = None\n",
    "        confidence = None\n",
    "        dec_device_id = None # id from decrypted payload\n",
    "        dec_description = row[\"DBDescription\"] # Default to DB version\n",
    "        dec_status_code = row[\"DBStatusCode\"] # Default to DB version\n",
    "        dec_date_published_utc = None # Top-level datePublished from decrypted payload\n",
    "\n",
    "        if encrypted_payload_db and not pd.isna(encrypted_payload_db) and encrypted_payload_db.strip() != \"[NULL]\":\n",
    "            decrypted_json = decrypt_payload_data(encrypted_payload_db, PRIVATE_KEY)\n",
    "\n",
    "            if decrypted_json:\n",
    "                dec_device_id = decrypted_json.get(\"id\")\n",
    "                dec_description = decrypted_json.get(\"description\", dec_description) # Use decrypted if available\n",
    "                dec_status_code = decrypted_json.get(\"statusCode\", dec_status_code) # Use decrypted if available\n",
    "\n",
    "                # Process top-level datePublished (milliseconds)\n",
    "                dec_date_published_ms = decrypted_json.get(\"datePublished\")\n",
    "                if dec_date_published_ms:\n",
    "                    try:\n",
    "                        dec_date_published_utc = datetime.fromtimestamp(dec_date_published_ms / 1000.0, tz=timezone.utc)\n",
    "                    except (ValueError, TypeError) as e:\n",
    "                        print(f\"Warning: Could not parse decrypted datePublished '{dec_date_published_ms}' for DB LocationID {db_location_id}: {e}\")\n",
    "\n",
    "                # Process nested payload\n",
    "                payload_data = decrypted_json.get(\"payload\")\n",
    "                if payload_data and isinstance(payload_data, dict):\n",
    "                    latitude = payload_data.get(\"latitude\")\n",
    "                    longitude = payload_data.get(\"longitude\")\n",
    "                    confidence = payload_data.get(\"confidence\")\n",
    "                    payload_timestamp_s = payload_data.get(\"timestamp\") # Assumed in seconds\n",
    "\n",
    "                    if payload_timestamp_s:\n",
    "                        try:\n",
    "                            actual_timestamp_utc = datetime.fromtimestamp(payload_timestamp_s, tz=timezone.utc)\n",
    "                        except (ValueError, TypeError) as e:\n",
    "                            print(f\"Warning: Could not parse decrypted payload.timestamp '{payload_timestamp_s}' for DB LocationID {db_location_id}: {e}\")\n",
    "                    else:\n",
    "                        print(f\"Warning: 'timestamp' not found in decrypted payload.payload for DB LocationID {db_location_id}\")\n",
    "\n",
    "                    if latitude is None or longitude is None:\n",
    "                        print(f\"Warning: 'latitude' or 'longitude' not found in decrypted payload.payload for DB LocationID {db_location_id}\")\n",
    "                else:\n",
    "                    print(f\"Warning: 'payload' object not found or not a dict in decrypted data for DB LocationID {db_location_id}\")\n",
    "            else:\n",
    "                print(f\"Warning: Failed to decrypt payload for DB LocationID {db_location_id}\")\n",
    "        elif encrypted_payload_db and encrypted_payload_db.strip() == \"[NULL]\":\n",
    "            print(f\"Info: EncryptedPayloadDB is '[NULL]' string for DB LocationID {db_location_id}. No decryption attempted.\")\n",
    "\n",
    "\n",
    "        processed_data_list.append({\n",
    "            \"DBLocationID\": db_location_id,\n",
    "            \"DeviceID\": dec_device_id if dec_device_id else db_device_id, # Prioritize decrypted, fallback to DB\n",
    "            \"ActualTimestampUTC\": actual_timestamp_utc, # This is payload.timestamp\n",
    "            \"Latitude\": latitude,\n",
    "            \"Longitude\": longitude,\n",
    "            \"Confidence\": confidence,\n",
    "            \"DecryptedDescription\": dec_description,\n",
    "            \"DecryptedStatusCode\": dec_status_code,\n",
    "            \"DecryptedDatePublishedUTC\": dec_date_published_utc, # Top-level datePublished\n",
    "            \"DBDatePublishedRaw\": row[\"DBDatePublished\"], # Keep original for reference if needed\n",
    "            \"EncryptedPayloadDB\": encrypted_payload_db\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(processed_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdf056-fcd5-409a-a902-3d0ac9e43855",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ecdf8-dccd-4ba2-a2af-d0ba41b206ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if not os.path.exists(DECRYPT_SCRIPT_PATH):\n",
    "        print(f\"CRITICAL ERROR: Decryption script not found at {DECRYPT_SCRIPT_PATH}\")\n",
    "        exit()\n",
    "\n",
    "    db_connection = connect_db()\n",
    "    if db_connection:\n",
    "        raw_df_from_db = fetch_raw_movement_data(db_connection)\n",
    "        db_connection.close()\n",
    "\n",
    "        if raw_df_from_db is not None and not raw_df_from_db.empty:\n",
    "            print(f\"Fetched {len(raw_df_from_db)} raw movement records from database.\")\n",
    "            print(\"Processing and decrypting payloads (this may take some time)...\")\n",
    "            \n",
    "            processed_df = process_movement_data(raw_df_from_db.copy())\n",
    "\n",
    "            print(\"\\n--- Processed Movement Data (First 5 Records) ---\")\n",
    "            print(processed_df.head())\n",
    "            print(\"\\n--- Processed Movement Data (Last 5 Records) ---\")\n",
    "            print(processed_df.tail())\n",
    "            print(\"\\n--- Processed Movement Data Info ---\")\n",
    "            processed_df.info()\n",
    "\n",
    "\n",
    "            # Further cleaning based on project plan (Section VI - Movement history data)\n",
    "            # Prioritize 'ActualTimestampUTC' (from payload.timestamp) and Lat/Lon from decrypted payload\n",
    "            cleaned_df = processed_df.dropna(subset=['ActualTimestampUTC', 'Latitude', 'Longitude'])\n",
    "            print(f\"\\nRemoved {len(processed_df) - len(cleaned_df)} rows with missing essential data (ActualTimestampUTC, Latitude, Longitude) after processing.\")\n",
    "            print(f\"Final dataset size for map-matching: {len(cleaned_df)} records.\")\n",
    "\n",
    "            if not cleaned_df.empty:\n",
    "                output_filename_parquet = \"danang_movement_processed_decrypted.parquet\"\n",
    "                try:\n",
    "                    cleaned_df.to_parquet(output_filename_parquet, index=False)\n",
    "                    print(f\"\\nProcessed and decrypted movement data saved to '{output_filename_parquet}'.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError saving processed data to Parquet: {e}\")\n",
    "\n",
    "                output_filename_csv = \"danang_movement_processed_decrypted.csv\"\n",
    "                try:\n",
    "                    cleaned_df.to_csv(output_filename_csv, index=False)\n",
    "                    print(f\"Processed and decrypted movement data saved to '{output_filename_csv}'.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError saving processed data to CSV: {e}\")\n",
    "            else:\n",
    "                print(\"\\nNo data left after cleaning. Output files not saved.\")\n",
    "        else:\n",
    "            print(\"No raw movement data fetched from database or DataFrame is empty.\")\n",
    "    else:\n",
    "        print(\"Could not connect to the database. Exiting.\")\n",
    "\n",
    "    print(\"\\nProcessing finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
